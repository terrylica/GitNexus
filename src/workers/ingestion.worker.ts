import * as Comlink from 'comlink';
import { GraphPipeline, type PipelineInput } from '../core/ingestion/pipeline.ts';
import { ParallelGraphPipeline } from '../core/ingestion/parallel-pipeline.ts';
import { isParallelParsingEnabled } from '../config/features.ts';
import type { KnowledgeGraph, GraphNode, GraphRelationship } from '../core/graph/types.ts';
import { ignoreService } from '../config/ignore-service.js';

export interface IngestionProgress {
  phase: 'structure' | 'parsing' | 'calls' | 'complete';
  message: string;
  progress: number;
  timestamp: number;
}

export interface IngestionResult {
  success: boolean;
  nodes?: GraphNode[];
  relationships?: GraphRelationship[];
  error?: string;
  stats?: {
    nodeStats: Record<string, number>;
    relationshipStats: Record<string, number>;
    callStats: { totalCalls: number; callTypes: Record<string, number> };
  };
  duration: number;
  graphType?: 'DualWriteKnowledgeGraph' | 'SimpleKnowledgeGraph';
  kuzuEnabled?: boolean;
}

export class IngestionWorker {
  private pipeline: GraphPipeline | ParallelGraphPipeline;
  private progressCallback?: (progress: IngestionProgress) => void;
  private currentGraph: KnowledgeGraph | null = null;

  constructor() {
    // Choose pipeline based on feature flag - same logic as main thread
    if (isParallelParsingEnabled()) {
      console.log('IngestionWorker: Using ParallelGraphPipeline');
      this.pipeline = new ParallelGraphPipeline();
    } else {
      console.log('IngestionWorker: Using GraphPipeline');
      this.pipeline = new GraphPipeline();
    }
  }

  public setProgressCallback(callback: (progress: IngestionProgress) => void): void {
    this.progressCallback = callback;
  }

  public async processRepository(input: PipelineInput): Promise<IngestionResult> {
    const startTime = Date.now();
    
    try {
      // Ensure ignore patterns are loaded in the worker before any processing starts
      try {
        await ignoreService.initialize();
      } catch (e) {
        console.warn('IngestionWorker: IgnoreService initialization failed, proceeding with defaults', e);
      }

      console.log('IngestionWorker: Starting processing with', input.filePaths.length, 'files');
      
      // Memory optimization: Create a copy of file contents and clear originals gradually
      const fileContentsMap = new Map(input.fileContents);
      
      // Initialize pipeline
      if (!this.pipeline) {
        if (isParallelParsingEnabled()) {
          this.pipeline = new ParallelGraphPipeline();
        } else {
          this.pipeline = new GraphPipeline();
        }
      }
      
      // Set up progress callback for the pipeline if it supports it
      if (this.pipeline instanceof ParallelGraphPipeline && this.progressCallback) {
        this.pipeline.setProgressCallback((progress) => {
          // Convert parallel pipeline progress to ingestion worker progress
          this.progressCallback!({
            phase: progress.phase as IngestionProgress['phase'],
            message: progress.message,
            progress: progress.progress,
            timestamp: progress.timestamp
          });
        });
      }

      // Progress tracking for regular pipeline
      let currentProgress = 0;
      const totalSteps = 3; // structure, parsing, calls
      
      const updateProgress = (phase: IngestionProgress['phase'], message: string, stepProgress: number) => {
        const overallProgress = (currentProgress / totalSteps) * 100 + (stepProgress / totalSteps);
        if (this.progressCallback && !(this.pipeline instanceof ParallelGraphPipeline)) {
          this.progressCallback({
            phase,
            message,
            progress: Math.min(overallProgress, 100),
            timestamp: Date.now()
          });
        }
      };

      // Run the pipeline with memory optimization
      if (!(this.pipeline instanceof ParallelGraphPipeline)) {
        updateProgress('structure', 'Analyzing project structure...', 0);
      }
      const graph = await this.pipeline.run({
        ...input,
        fileContents: fileContentsMap
      });
      
      // Store the graph for later access
      this.currentGraph = graph;
      
      // Note: Keeping file contents available for UI components
      // fileContentsMap.clear(); // Commented out to preserve file contents for SourceViewer
      
      const duration = Date.now() - startTime;
      
      console.log('IngestionWorker: Processing completed successfully');
      console.log(`Graph contains ${graph.nodes.length} nodes and ${graph.relationships.length} relationships`);
      
      // Calculate statistics
      const nodeStats: Record<string, number> = {};
      const relationshipStats: Record<string, number> = {};
      
      graph.nodes.forEach(node => {
        nodeStats[node.label] = (nodeStats[node.label] || 0) + 1;
      });
      
      graph.relationships.forEach(rel => {
        relationshipStats[rel.type] = (relationshipStats[rel.type] || 0) + 1;
      });

      // Determine graph type and KuzuDB status
      const graphType = graph.constructor.name === 'DualWriteKnowledgeGraph' ? 'DualWriteKnowledgeGraph' : 'SimpleKnowledgeGraph';
      const kuzuEnabled = graphType === 'DualWriteKnowledgeGraph' && 'isKuzuDBEnabled' in graph && (graph as any).isKuzuDBEnabled();
      
      console.log(`ðŸ“Š Worker returning graph type: ${graphType}, KuzuDB enabled: ${kuzuEnabled}`);
      
      // Return only serializable data - nodes and relationships arrays
      return {
        success: true,
        nodes: graph.nodes,
        relationships: graph.relationships,
        stats: {
          nodeStats,
          relationshipStats,
          callStats: { totalCalls: 0, callTypes: {} }
        },
        duration,
        graphType: graphType as 'DualWriteKnowledgeGraph' | 'SimpleKnowledgeGraph',
        kuzuEnabled
      };
    } catch (error) {
      console.error('IngestionWorker: Processing failed:', error);
      
      const duration = Date.now() - startTime;
      
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error occurred during processing',
        duration
      };
    }
  }

  public async processFiles(
    projectName: string,
    files: { path: string; content: string }[]
  ): Promise<IngestionResult> {
    const fileContents = new Map<string, string>();
    const filePaths: string[] = [];
    
    for (const file of files) {
      filePaths.push(file.path);
      fileContents.set(file.path, file.content);
    }
    
    const input: PipelineInput = {
      projectRoot: '/',
      projectName,
      filePaths,
      fileContents
    };
    
    return this.processRepository(input);
  }

  public async validateRepository(input: PipelineInput): Promise<{ valid: boolean; errors: string[] }> {
    const errors: string[] = [];
    
    try {
      this.validateInput(input);
      
      // Additional validation checks
      if (input.filePaths.length === 0) {
        errors.push('No files provided for processing');
      }
      
      if (input.fileContents.size === 0) {
        errors.push('No file contents provided');
      }
      
      // Check for source files (Python, JavaScript, TypeScript)
      const sourceFiles = input.filePaths.filter(path => 
        path.endsWith('.py') || 
        path.endsWith('.js') || 
        path.endsWith('.jsx') || 
        path.endsWith('.ts') || 
        path.endsWith('.tsx')
      );
      if (sourceFiles.length === 0) {
        errors.push('No source files found in the repository (Python, JavaScript, or TypeScript)');
      }
      
      // Validate file contents exist
      for (const filePath of input.filePaths) {
        if (!input.fileContents.has(filePath)) {
          errors.push(`Missing content for file: ${filePath}`);
        }
      }
      
      return {
        valid: errors.length === 0,
        errors
      };
      
    } catch (error) {
      errors.push(error instanceof Error ? error.message : 'Validation failed');
      return {
        valid: false,
        errors
      };
    }
  }

  public getWorkerInfo(): { version: string; capabilities: string[] } {
    return {
      version: '1.0.0',
      capabilities: [
        'python-parsing',
        'javascript-parsing',
        'typescript-parsing',
        'tsx-parsing',
        'structure-analysis',
        'call-resolution',
        'ast-caching',
        'progress-reporting',
        'config-file-parsing',
        'import-resolution'
      ]
    };
  }

  private validateInput(input: PipelineInput): void {
    if (!input.projectName || input.projectName.trim().length === 0) {
      throw new Error('Project name is required');
    }
    
    if (!input.projectRoot || input.projectRoot.trim().length === 0) {
      throw new Error('Project root is required');
    }
    
    if (!Array.isArray(input.filePaths)) {
      throw new Error('File paths must be an array');
    }
    
    if (!(input.fileContents instanceof Map)) {
      throw new Error('File contents must be a Map');
    }
  }

  public terminate(): void {
    // Cleanup resources if needed
    console.log('Ingestion worker terminated');
  }

}

// Expose the worker class via Comlink
const worker = new IngestionWorker();
Comlink.expose(worker); 
